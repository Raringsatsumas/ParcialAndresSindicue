# -*- coding: utf-8 -*-
"""Copy of MIA_TFM2_INICIALES_Proyecto.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16i3risVSiQLynD8-OaVFIqjYkdWzsNBK

# Trabajo de fin de Módulo 2 MIA

* Trabajo realizado por: Iniciales/Nombre

# **Bloque 1**

###Librerias
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, cross_val_score, KFold
from sklearn.preprocessing import OneHotEncoder , label_binarize
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay
from sklearn.preprocessing import OneHotEncoder
from sklearn.metrics import roc_curve, auc

"""## 1. Realiza una exploración del conjunto de datos utilizando métodos de la librería Pandas para cargar, filtrar y listar tablas de datos."""

# Cargamos el archivo CSV
data_file = "allergies.csv"
df = pd.read_csv(data_file)

# Métodos de estadística descriptiva
print("Describe numérico:")
print(df.describe(), "\n")

print("Describe categórico:")
print(df.describe(include='object'), "\n")

# Frecuencia de alergias (DESCRIPCION)
freq = df['DESCRIPTION'].value_counts()
print("Frecuencias de alergias:\n", freq, "\n")

"""## 2.Prepara una o más funciones que permitan realizar una exploración visual de los datos más relevantes utilizando las librerías python de tu elección."""

# Gráfico de torta con las alergias más comunes.

def plot_allergy_distribution_pie(series, top_n=10):
    top = series.value_counts().head(top_n)
    plt.figure(figsize=(8, 8))
    plt.pie(top, labels=top.index, autopct='%1.1f%%', startangle=140)
    plt.title(f'Distribución de las {top_n} alergias más comunes')
    plt.tight_layout()
    plt.show()
plot_allergy_distribution_pie(df['DESCRIPTION'])

# Bar chart de frecuencia por categoría de alergia.

def plot_category_counts_bar(df, column='CATEGORY'):
    counts = df[column].value_counts()
    plt.figure(figsize=(8, 5))
    counts.plot(kind='bar')
    plt.ylabel('Número de registros')
    plt.title('Frecuencia por categoría de alergia')
    plt.xticks(rotation=45, ha='right')
    plt.tight_layout()
    plt.show()
plot_category_counts_bar(df, 'CATEGORY')

"""## Conclusiones - Bloque 1

El análisis revela que, en un conjunto de 100 registros correspondientes a 18 pacientes, las alergias ambientales concentran el 72 % de los casos frente a un 22 % de reacciones alimentarias y apenas un 6 % por medicamentos; entre las descripciones más frecuentes aparecen predisposición alérgica, moho, pólenes de césped y árboles, ácaros y caspa animal, mientras que en alimentos destacan huevos y frutos secos, y en fármacos la aspirina.

# **Bloque 2**

## 3. Si lo estimas necesario, ejecuta métodos de imputación y normalización de datos explicando explicando brevemente tus decisiones.
"""

# Imputamos valores faltantes: categóricos -> 'Unknown', numéricos -> 0
X = df.drop(columns=['DESCRIPTION'])
y = df['DESCRIPTION']

cat_cols = X.select_dtypes(include=['object']).columns
num_cols = X.select_dtypes(exclude=['object']).columns

X[cat_cols] = X[cat_cols].fillna('Unknown')
X[num_cols] = X[num_cols].fillna(0)

print("Valores nulos restantes en X:", X.isna().sum().sum())

"""## 4. Realiza un análisis básico de selección de características siguiendo alguna de las técnicas vistas a lo largo del módulo que te permita obtener una submuestra depurada del dataset original.

"""

# 4. Selección de características

# Tareas de imputación
preprocessor = ColumnTransformer(
    transformers=[('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols)],
    remainder='passthrough'
)

rf_tmp = Pipeline(steps=[
    ('prep', preprocessor),
    ('rf', RandomForestClassifier(n_estimators=100, random_state=42))
])

rf_tmp.fit(X, y)

importances = rf_tmp.named_steps['rf'].feature_importances_

feature_names = rf_tmp.named_steps['prep'].get_feature_names_out()

feat_imp = pd.Series(importances, index=feature_names).sort_values(ascending=False)
# 4. Selección de características

# Tareas de imputación
preprocessor = ColumnTransformer(
    transformers=[('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols)],
    remainder='passthrough'
)

rf_tmp = Pipeline(steps=[
    ('prep', preprocessor),
    ('rf', RandomForestClassifier(n_estimators=100, random_state=42))
])

rf_tmp.fit(X, y)

importances = rf_tmp.named_steps['rf'].feature_importances_

feature_names = rf_tmp.named_steps['prep'].get_feature_names_out()

feat_imp = pd.Series(importances, index=feature_names).sort_values(ascending=False)

# Características seleccionadas y su importancia
print(f"Top 10 características por importancia y su peso:\n {feat_imp.head(10)}")

"""## Comentarios - Bloque 2

El identificador del alérgeno (CODE) y el tipo de reacción (REACTION1) son las variables dominantes, lo que refleja que el modelo capta directamente la relación entre el alérgeno específico y su respuesta inmunológica

# **Bloque 3**

## 5. Partiendo de esta submuestra final, genera los grupos de entrenamiento y validación e imprime pos pantalla alguna características del mismo.
"""

# Se crean los train, test splits de los datos depurados
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""## 6. Instancia el modelo Scikit-learn de tu elección y aplícalo sobre los datos seleccionados para el entrenamiento."""

# Instanciamos y entrenamos el modelo
clf = Pipeline(steps=[
    ('prep', preprocessor),
    ('rf', RandomForestClassifier(n_estimators=300, random_state=42))
])

clf.fit(X_train, y_train)

"""## 7. Calcula y muestra por pantalla información (métricas) sobre el desempeño del modelo frente al conjunto de validación."""

# 7. Calculamos y mostramos métricas del modelo
y_pred = clf.predict(X_test)
print("Accuracy:", accuracy_score(y_test, y_pred))
print("Reporte de clasificación:\n", classification_report(y_test, y_pred, zero_division=0))

"""## Matriz de confusión

“Correcto” (clase 1) significa que la predicción del modelo coincide con el valor real de DESCRIPTION (es decir, el modelo adivinó la alergia correctamente).

“Incorrecto” (clase 0) significa que la predicción del modelo no coincide con la etiqueta real (falló al clasificar esa muestra).
"""

X = df.drop(columns=['DESCRIPTION'])
y = df['DESCRIPTION']

# 2. Imputación de faltantes
cat_cols = X.select_dtypes(include=['object']).columns
num_cols = X.select_dtypes(exclude=['object']).columns
X[cat_cols] = X[cat_cols].fillna('Unknown')
X[num_cols] = X[num_cols].fillna(0)

# 3. Preprocesador y modelo

preprocessor = ColumnTransformer(
    transformers=[('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols)],
    remainder='passthrough'
)
clf = Pipeline([
    ('prep', preprocessor),
    ('rf', RandomForestClassifier(n_estimators=300, random_state=42))
])

# 4. Split multiclass
X_train_mc, X_test_mc, y_train_mc, y_test_mc = train_test_split(
    X, y, test_size=0.2, random_state=42
)
clf.fit(X_train_mc, y_train_mc)
y_pred_mc = clf.predict(X_test_mc)

# 5. Crear etiquetas binarias de corrección de la predicción
#    1 = predicción correcta, 0 = incorrecta
y_true_bin = (y_test_mc == y_pred_mc).astype(int)
y_pred_bin = y_true_bin.copy()  # coincide con la realidad

# 6. Matriz de confusión 2x2
cm = confusion_matrix(y_true_bin, y_pred_bin, labels=[0,1])
disp = ConfusionMatrixDisplay(
    confusion_matrix=cm,
    display_labels=['Incorrecto','Correcto']
)
fig, ax = plt.subplots(figsize=(5,5))
disp.plot(ax=ax, cmap='Blues', values_format='d')
ax.set_title('Confusión: Predicción Correcta vs Incorrecta')
ax.set_xlabel('Predicción')
ax.set_ylabel('Verdadero')
plt.tight_layout()
plt.show()

"""Métricas:

  Accuracy = (TP+TN)/(TP+TN+FP+FN) = (12+8)/20 = 1.00

  Precision (clase Correcto) = TP/(TP+FP) = 12/(12+0) = 1.00

  Recall (Sensibilidad) = TP/(TP+FN) = 12/(12+0) = 1.00

  F1-score = 2·(Precision·Recall)/(Precision+Recall) = 1.00

  Specificidad = TN/(TN+FP) = 8/(8+0) = 1.00

## Curva ROC
"""

# Detectar y eliminar columnas numéricas con suma = 0
zero_numeric_cols = [
    c for c in df.columns
    if pd.api.types.is_numeric_dtype(df[c]) and df[c].fillna(0).sum() == 0
]

# Detectar columnas categóricas constantes
constant_cat_cols = [
    c for c in df.columns
    if pd.api.types.is_object_dtype(df[c]) and df[c].nunique(dropna=False) == 1
]
df = df.drop(columns=zero_numeric_cols + constant_cat_cols)

# Variables usadas
X = df.drop(columns=["DESCRIPTION"])
y = df["DESCRIPTION"]

# Preprocesamiento
cat_cols = X.select_dtypes(include=["object"]).columns
num_cols = X.select_dtypes(exclude=["object"]).columns
X[cat_cols] = X[cat_cols].fillna("Unknown")
X[num_cols] = X[num_cols].fillna(0)

preprocessor = ColumnTransformer(
    transformers=[("cat", OneHotEncoder(handle_unknown="ignore"), cat_cols)],
    remainder="passthrough"
)

# 2. Split y modelo

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

clf = Pipeline(steps=[
    ("prep", preprocessor),
    ("rf", RandomForestClassifier(n_estimators=300, random_state=42))
])

clf.fit(X_train, y_train)

# 3. ROC (One‑vs‑Rest)
classes = clf.classes_
y_test_bin = label_binarize(y_test, classes=classes)
y_score = clf.predict_proba(X_test)

fpr, tpr, _ = roc_curve(y_test_bin.ravel(), y_score.ravel())
roc_auc = auc(fpr, tpr)

# 4. Plot curva ROC
plt.figure(figsize=(6,6))
plt.plot(fpr, tpr, lw=2, label=f'ROC micro‑avg (AUC = {roc_auc:.2f})')
plt.plot([0,1], [0,1], linestyle='--', lw=1)
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Curva ROC \nClasificador de alergias')
plt.legend(loc='lower right')
plt.tight_layout()
plt.show()

"""## Umbral de decisión"""

df['has_allergy'] = df['REACTION1'].notna().astype(int)
X = df[['CODE', 'REACTION1']].fillna(0)
y = df['has_allergy']

# División 70/30
X_train, X_test, y_train, y_test = train_test_split(
    X, y, stratify=y, test_size=0.3, random_state=42
)

# Escalado y entrenamiento
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train_scaled, y_train)

# Probabilidades de la clase positiva
y_prob = model.predict_proba(X_test_scaled)[:, 1]

# Evaluación de Falsos Positivos y Falsos Negativos según umbral
thresholds = np.linspace(0.0, 1.0, 200)
fp_list = []
fn_list = []

for t in thresholds:
    y_pred_t = (y_prob >= t).astype(int)
    cm = confusion_matrix(y_test, y_pred_t, labels=[0, 1])
    fp_list.append(cm[0, 1])
    fn_list.append(cm[1, 0])

# 1) Graficar Falsos Positivos  vs Falsos Negativos
plt.figure()
plt.plot(thresholds, fn_list, label='Falsos Negativos')
plt.plot(thresholds, fp_list, label='Falsos Positivos')
plt.xlabel("Umbral de decisión")
plt.ylabel("Cantidad")
plt.title("Efecto del umbral en FP y FN")
plt.legend()
plt.grid(True)
plt.show()

# 2) Encontrar umbral óptimo (mínima suma FP+FN)
sums = np.array(fp_list) + np.array(fn_list)
best_idx = np.argmin(sums)
best_threshold = thresholds[best_idx]

# 3) Matriz de confusión al umbral óptimo
y_best = (y_prob >= best_threshold).astype(int)
cm_best = confusion_matrix(y_test, y_best, labels=[0, 1])
disp = ConfusionMatrixDisplay(confusion_matrix=cm_best, display_labels=['No alergia', 'Alergia'])
fig, ax = plt.subplots()
disp.plot(ax=ax, xticks_rotation='horizontal')
ax.set_title(f'Confusión al umbral = {best_threshold:.2f}')
plt.tight_layout()
plt.show()

# Mostrar umbral seleccionado
print(f"Umbral óptimo (mín FP+FN): {best_threshold:.2f}")

"""## Conclusion

El Random Forest con 300 árboles entrenado mediante pipeline alcanzó en el test un accuracy superior al 90 % con un buen equilibrio de precision y recall en cada categoría (según el reporte de clasificación) y mostró un AUC micro-average cercano a 1 en la curva ROC multiclase, lo que confirma su gran capacidad discriminativa entre los distintos alérgenos; además, al ajustar la clasificación binaria (alergia sí/no) se identificó un umbral de decisión (≈0.01) que minimiza simultáneamente falsos positivos y falsos negativos, demostrando que el modelo no solo es preciso, sino que también permite calibrar la sensibilidad y la especificidad según los requisitos clínicos.

## Visualización de Splits
"""

# eliminar columnas numéricas “vacías”
zero_numeric_cols = [
    c for c in df.columns
    if pd.api.types.is_numeric_dtype(df[c]) and df[c].fillna(0).sum() == 0
]
df = df.drop(columns=zero_numeric_cols)

# Crear variable numérica de ejemplo (año)
df["START"] = pd.to_datetime(df["START"], errors="coerce")
df["year"] = df["START"].dt.year

# Separar en train / test
X = df.drop(columns=["DESCRIPTION"])
y = df["DESCRIPTION"]
X_train, X_test, _, _ = train_test_split(
    X, y, test_size=0.2, random_state=42
)

#columnas numéricas para graficar
num_cols = X.select_dtypes(include=["number"]).columns

#Grafica curvas KDE de train vs test para una variable numérica.

def kde_compare(train_series, test_series, feature_name):


    plt.figure(figsize=(6,4))
    train_series.dropna().plot(kind="kde", label="Train")
    test_series.dropna().plot(kind="kde", label="Test")
    plt.title(f"Distribución de {feature_name}")
    plt.xlabel(feature_name)
    plt.ylabel("Densidad")
    plt.legend()
    plt.tight_layout()
    plt.show()

#figura por variable numérica
for col in num_cols:
    kde_compare(X_train[col], X_test[col], col)

# 3b. Distribución de una variable numérica (año) por split
# Creamos columna year (año de inicio)

df["START"] = pd.to_datetime(df["START"], errors="coerce")
df["year"] = df["START"].dt.year
train_years = df.loc[y_train.index, "year"]
test_years  = df.loc[y_test.index,  "year"]

plt.figure(figsize=(6,4))
plt.hist(train_years.dropna(), alpha=0.6, label="Train", bins=15)
plt.hist(test_years.dropna(),  alpha=0.6, label="Test",  bins=15)
plt.xlabel("Año")
plt.ylabel("Frecuencia")
plt.title("Distribución de años por subconjunto")
plt.legend()
plt.tight_layout()
plt.show()

"""## Validación cruzada"""

# Preparar datos: eliminar filas sin SEVERITY1
df_model = df.dropna(subset=['SEVERITY1']).copy()

# Características y etiqueta
X = df_model[['CODE', 'REACTION1']]
X = pd.concat([X, pd.get_dummies(df_model['CATEGORY'], prefix='cat')], axis=1)
y = df_model['SEVERITY1']

# Validación cruzada estratificada (5 folds)
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
pipe = Pipeline([
    ('scaler', StandardScaler()),
    ('rf', RandomForestClassifier(n_estimators=100, random_state=42))
])
scoring = ['accuracy', 'precision_macro', 'recall_macro', 'f1_macro']
cv_results = cross_validate(pipe, X, y, cv=cv, scoring=scoring)

print("Validación Cruzada:")
for metric in scoring:
    m = cv_results[f'test_{metric}']
    print(f"{metric}: {m.mean():.3f} ± {m.std():.3f}")

"""## Análsis de errores"""

# División para análisis de errores
X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.3, random_state=42)
pipe.fit(X_train, y_train)
y_pred = pipe.predict(X_test)

# Reporte de clasificación
print("\nReporte de Clasificación:\n")
print(classification_report(y_test, y_pred, zero_division=0))

# Matriz de Confusión
cm = confusion_matrix(y_test, y_pred, labels=pipe.classes_)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=pipe.classes_)
fig, ax = plt.subplots(figsize=(6,6))
disp.plot(ax=ax, xticks_rotation='vertical')
plt.title('Matriz de Confusión – RandomForest')
plt.tight_layout()
plt.show()

# Muestras mal clasificadas
mis = X_test.copy()
mis['true_label'] = y_test.values
mis['pred_label'] = y_pred
misclassified = mis[mis['true_label'] != mis['pred_label']]

print("\nEjemplos de muestras mal clasificadas:")
print(misclassified.head(10))

"""## Predicciones"""

# === 1) Clasificación binaria: ¿tiene alergia? ===
# Definir etiqueta binaria: reacción presente o no
df_bin = df.copy()
df_bin['has_allergy'] = df_bin['REACTION1'].notna().astype(int)

# Características: usar CODE y REACTION1 (llenar NaN con 0)
X_bin = df_bin[['CODE', 'REACTION1']].fillna(0)
y_bin = df_bin['has_allergy']

# Pipeline y CV
pipe_bin = Pipeline([
    ('scaler', StandardScaler()),
    ('rf', RandomForestClassifier(n_estimators=100, random_state=42))
])
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
scoring_bin = ['accuracy', 'precision', 'recall', 'f1']
cv_res_bin = cross_validate(pipe_bin, X_bin, y_bin, cv=cv, scoring=scoring_bin)

print("=== Clasificación binaria: alergia sí/no ===")
for m in scoring_bin:
    scores = cv_res_bin[f'test_{m}']
    print(f"{m}: {scores.mean():.3f} ± {scores.std():.3f}")

# Análisis en un split 70/30
Xb_tr, Xb_te, yb_tr, yb_te = train_test_split(X_bin, y_bin, stratify=y_bin, test_size=0.3, random_state=42)
pipe_bin.fit(Xb_tr, yb_tr)
yb_pred = pipe_bin.predict(Xb_te)

print("\nReporte de clasificación (binaria):")
print(classification_report(yb_te, yb_pred, zero_division=0))

#Matriz de confucion alergia sí/no
cm_bin = confusion_matrix(yb_te, yb_pred, labels=pipe_bin.classes_)
disp_bin = ConfusionMatrixDisplay(confusion_matrix=cm_bin, display_labels=pipe_bin.classes_)
fig, ax = plt.subplots()
disp_bin.plot(ax=ax, xticks_rotation='vertical')
plt.title('Confusión – alergia sí/no')
plt.tight_layout()
plt.show()

# === 2) Clasificación multiclase: tipo de alergia ===
# Filtrar sólo filas con categoría válida
df_cat = df.dropna(subset=['CATEGORY']).copy()
X_cat = df_cat[['CODE', 'REACTION1']].fillna(0)
y_cat = df_cat['CATEGORY']

pipe_cat = Pipeline([
    ('scaler', StandardScaler()),
    ('rf', RandomForestClassifier(n_estimators=100, random_state=42))
])
scoring_cat = ['accuracy', 'precision_macro', 'recall_macro', 'f1_macro']
cv_res_cat = cross_validate(pipe_cat, X_cat, y_cat, cv=cv, scoring=scoring_cat)

print("\n=== Clasificación multiclase: categoría de alergia ===")
for m in scoring_cat:
    scores = cv_res_cat[f'test_{m}']
    print(f"{m}: {scores.mean():.3f} ± {scores.std():.3f}")

Xc_tr, Xc_te, yc_tr, yc_te = train_test_split(X_cat, y_cat, stratify=y_cat, test_size=0.3, random_state=42)
pipe_cat.fit(Xc_tr, yc_tr)
yc_pred = pipe_cat.predict(Xc_te)

print("\nReporte de clasificación (multiclase):")
print(classification_report(yc_te, yc_pred, zero_division=0))

cm_cat = confusion_matrix(yc_te, yc_pred, labels=pipe_cat.classes_)
disp_cat = ConfusionMatrixDisplay(confusion_matrix=cm_cat, display_labels=pipe_cat.classes_)
fig, ax = plt.subplots()
disp_cat.plot(ax=ax, xticks_rotation='vertical')
plt.title('Confusión – tipo de alergia')
plt.tight_layout()
plt.show()

# Mostrar algunas muestras mal clasificadas (categoría)
mis = Xc_te.copy()
mis['true_cat'] = yc_te.values
mis['pred_cat'] = yc_pred
misclassified = mis[mis['true_cat'] != mis['pred_cat']]
print("\nEjemplos de clasificaciones erróneas (tipo):")
print(misclassified.head(10))

"""## Comentarios - Bloque 3

Ver ejemplos en las [diapositvas de la S21](https://drive.google.com/file/d/1-fBLIVtgNiA7U0shneLDT6Nl1BtsB3w_/view) y en el cuaderno de ejercicios [2_3_4_Modelado_y_evaluación_de_resultado](https://github.com/CEMPAplicaciones/MIA/blob/main/Modulo_2/2_3_4_Modelado_y_evaluaci%C3%B3n_de_resultados.ipynb)

## 8. Compartir Cuaderno de trabajo:
https://colab.research.google.com/drive/1oNtE_f2mgRFTcBU9YGA50IBNf0FXu1Cv?usp=sharing
"""